# GuÃ­a de Testing - Materials Hub

Esta guÃ­a explica la estrategia de testing completa del proyecto Materials Hub.

## ğŸ“š Tabla de Contenidos

1. [Tipos de Tests](#tipos-de-tests)
2. [Ejecutar Tests](#ejecutar-tests)
3. [Test Coverage](#test-coverage)
4. [Estructura de Tests](#estructura-de-tests)
5. [Mejores PrÃ¡cticas](#mejores-prÃ¡cticas)

---

## ğŸ§ª Tipos de Tests

### 1. Unit Tests (Tests Unitarios)
**UbicaciÃ³n:** `app/modules/*/tests/test_unit.py`

**QuÃ© testean:** Funciones y mÃ©todos individuales de forma aislada.

**CaracterÃ­sticas:**
- âœ… RÃ¡pidos (< 100ms por test)
- âœ… Sin dependencias externas (usan mocks)
- âœ… No requieren base de datos
- âœ… Aislados y predecibles

**Ejemplo:**
```bash
# Ejecutar solo unit tests
pytest -m unit

# Ejecutar unit tests de un mÃ³dulo especÃ­fico
pytest app/modules/zenodo/tests/test_unit.py
```

### 2. Integration Tests (Tests de IntegraciÃ³n)
**UbicaciÃ³n:** `app/modules/*/tests/test_integration.py`

**QuÃ© testean:** InteracciÃ³n entre mÃºltiples componentes (servicios, repositorios, base de datos).

**CaracterÃ­sticas:**
- â±ï¸ MÃ¡s lentos (100ms - 1s por test)
- ğŸ—„ï¸ Requieren base de datos de test
- ğŸ”— Prueban flujos completos
- ğŸ’¾ Usan datos reales en DB de test

**Ejemplo:**
```bash
# Ejecutar solo integration tests
pytest -m integration

# Ejecutar integration tests de autenticaciÃ³n
pytest app/modules/auth/tests/test_integration.py
```

### 3. GUI Tests / E2E (Tests de Interfaz con Selenium)
**UbicaciÃ³n:** `app/modules/*/tests/test_selenium.py`

**QuÃ© testean:** Interfaz de usuario completa en navegador real.

**CaracterÃ­sticas:**
- ğŸŒ Muy lentos (varios segundos por test)
- ğŸŒ Requieren navegador (Chrome/Firefox)
- ğŸ–±ï¸ Simulan interacciÃ³n de usuario real
- ï¿½ï¿½ Pueden tomar capturas de pantalla

**Ejemplo:**
```bash
# Ejecutar solo tests de Selenium
pytest -m selenium

# Ejecutar con navegador visible (no headless)
pytest -m selenium --headed
```

### 4. Load Tests (Tests de Carga con Locust)
**UbicaciÃ³n:** `tests/locust/`

**QuÃ© testean:** Rendimiento y capacidad del sistema bajo carga.

**CaracterÃ­sticas:**
- ğŸ“Š Miden rendimiento
- ğŸ‘¥ Simulan mÃºltiples usuarios concurrentes
- â±ï¸ Miden tiempo de respuesta
- ğŸ’ª Encuentran cuellos de botella

**Ejemplo:**
```bash
# Ejecutar load tests
locust -f tests/locust/locustfile.py --host=http://localhost:5000

# Abrir interfaz web de Locust
# â†’ http://localhost:8089
```

---

## ğŸš€ Ejecutar Tests

### Comandos BÃ¡sicos

```bash
# Ejecutar TODOS los tests
pytest

# Ejecutar con verbose output
pytest -v

# Ejecutar tests de un mÃ³dulo especÃ­fico
pytest app/modules/auth/tests/

# Ejecutar un archivo de test especÃ­fico
pytest app/modules/dataset/tests/test_unit.py

# Ejecutar una funciÃ³n de test especÃ­fica
pytest app/modules/auth/tests/test_unit.py::test_login_success

# Ejecutar tests que coincidan con un patrÃ³n
pytest -k "login"
```

### Por Tipo de Test

```bash
# Solo unit tests (rÃ¡pidos)
pytest -m unit

# Solo integration tests
pytest -m integration

# Solo Selenium tests
pytest -m selenium

# Excluir Selenium tests (mÃ¡s comÃºn)
pytest -m "not selenium"

# Tests rÃ¡pidos (unit + algunos integration)
pytest -m "unit or fast"

# Smoke tests (funcionalidad crÃ­tica)
pytest -m smoke
```

### Opciones Ãštiles

```bash
# Detener en primer fallo
pytest -x

# Ejecutar Ãºltimo test que fallÃ³
pytest --lf

# Ejecutar tests fallidos primero
pytest --ff

# Ejecutar en paralelo (mÃ¡s rÃ¡pido)
pytest -n auto

# Mostrar print statements
pytest -s

# Mostrar variables locales en fallos
pytest --showlocals

# Modo verbose con duraciÃ³n de tests
pytest -v --durations=10
```

---

## ğŸ“Š Test Coverage

### Generar Reporte de Coverage

```bash
# Ejecutar tests con coverage
pytest --cov=app --cov=rosemary --cov=core

# Generar reporte HTML
pytest --cov=app --cov-report=html

# Abrir reporte en navegador
open htmlcov/index.html  # macOS
xdg-open htmlcov/index.html  # Linux
start htmlcov/index.html  # Windows

# Generar reporte XML (para CI/CD)
pytest --cov=app --cov-report=xml

# Mostrar lÃ­neas no cubiertas
pytest --cov=app --cov-report=term-missing
```

### Coverage por MÃ³dulo

```bash
# Coverage de mÃ³dulo especÃ­fico
pytest app/modules/auth/tests/ --cov=app.modules.auth

# Coverage mÃ­nimo requerido (falla si < 70%)
pytest --cov=app --cov-fail-under=70
```

### Interpretar Resultados

```
Name                                 Stmts   Miss  Cover   Missing
------------------------------------------------------------------
app/modules/auth/services.py           45      3    93%   23, 45-46
app/modules/dataset/models.py          78      0   100%
app/modules/zenodo/services.py        120     25    79%   45-52, 89-95
------------------------------------------------------------------
TOTAL                                 243     28    88%
```

- **Stmts**: LÃ­neas de cÃ³digo
- **Miss**: LÃ­neas no ejecutadas por tests
- **Cover**: Porcentaje de cobertura
- **Missing**: NÃºmeros de lÃ­nea no cubiertos

---

## ğŸ“ Estructura de Tests

```
materials-hub/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ modules/
â”‚       â”œâ”€â”€ auth/
â”‚       â”‚   â””â”€â”€ tests/
â”‚       â”‚       â”œâ”€â”€ __init__.py
â”‚       â”‚       â”œâ”€â”€ test_unit.py           # Unit tests
â”‚       â”‚       â”œâ”€â”€ test_integration.py    # Integration tests
â”‚       â”‚       â””â”€â”€ test_selenium.py       # GUI tests
â”‚       â”œâ”€â”€ dataset/
â”‚       â”‚   â””â”€â”€ tests/
â”‚       â”‚       â”œâ”€â”€ test_unit.py
â”‚       â”‚       â””â”€â”€ test_integration.py
â”‚       â”œâ”€â”€ explore/
â”‚       â”‚   â””â”€â”€ tests/
â”‚       â”‚       â””â”€â”€ test_unit.py
â”‚       â””â”€â”€ zenodo/
â”‚           â””â”€â”€ tests/
â”‚               â””â”€â”€ test_unit.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ locust/
â”‚   â”‚   â”œâ”€â”€ locustfile.py              # Load tests
â”‚   â”‚   â””â”€â”€ README.md
â”‚   â””â”€â”€ README.md (este archivo)
â”œâ”€â”€ pytest.ini                          # ConfiguraciÃ³n de pytest
â”œâ”€â”€ .coveragerc                         # ConfiguraciÃ³n de coverage
â””â”€â”€ htmlcov/                            # Reportes de coverage (generado)
```

---

## âœ… Mejores PrÃ¡cticas

### 1. Nomenclatura

```python
# âœ… BUENO
def test_login_success_redirects_to_home():
    """Test that successful login redirects to home page"""
    pass

def test_create_dataset_with_invalid_title_raises_error():
    """Test that creating dataset with invalid title raises ValidationError"""
    pass

# âŒ MALO
def test1():
    pass

def test_stuff():
    pass
```

### 2. Estructura de Tests (Arrange-Act-Assert)

```python
def test_user_creation():
    # Arrange - Preparar datos
    email = "test@example.com"
    password = "secure123"

    # Act - Ejecutar acciÃ³n
    user = User(email=email, password=password)
    db.session.add(user)
    db.session.commit()

    # Assert - Verificar resultado
    assert user.id is not None
    assert user.email == email

    # Cleanup - Limpiar
    db.session.delete(user)
    db.session.commit()
```

### 3. Usar Fixtures

```python
@pytest.fixture
def sample_user():
    """Fixture que crea un usuario de prueba"""
    user = User(email="fixture@example.com", password="test123")
    db.session.add(user)
    db.session.commit()
    yield user
    db.session.delete(user)
    db.session.commit()

def test_with_fixture(sample_user):
    """Test que usa el fixture"""
    assert sample_user.email == "fixture@example.com"
```

### 4. Mocking para Unit Tests

```python
from unittest.mock import Mock, patch

@patch('app.modules.zenodo.services.requests.get')
def test_zenodo_connection(mock_get):
    """Test con mock para evitar llamadas HTTP reales"""
    # Configurar mock
    mock_response = Mock()
    mock_response.status_code = 200
    mock_get.return_value = mock_response

    # Ejecutar test
    service = ZenodoService()
    result = service.test_connection()

    # Verificar
    assert result is True
    mock_get.assert_called_once()
```

### 5. Markers para Categorizar

```python
@pytest.mark.unit
def test_fast_unit_test():
    """Test rÃ¡pido unitario"""
    pass

@pytest.mark.integration
def test_database_integration():
    """Test de integraciÃ³n con DB"""
    pass

@pytest.mark.slow
def test_complex_operation():
    """Test que toma varios segundos"""
    pass

@pytest.mark.smoke
def test_critical_functionality():
    """Test de funcionalidad crÃ­tica"""
    pass
```

### 6. ParametrizaciÃ³n

```python
@pytest.mark.parametrize("email,password,expected", [
    ("test@example.com", "valid123", True),
    ("bad@example.com", "wrong", False),
    ("", "password", False),
    ("test@example.com", "", False),
])
def test_login_scenarios(email, password, expected):
    """Test mÃºltiples escenarios de login"""
    result = authenticate(email, password)
    assert result == expected
```

---

## ğŸ¯ Objetivos de Coverage

| MÃ³dulo | Coverage MÃ­nimo | Coverage Ideal |
|--------|----------------|----------------|
| Servicios | 80% | 95% |
| Repositorios | 75% | 90% |
| Modelos | 70% | 85% |
| Routes | 60% | 80% |
| Forms | 50% | 70% |
| **TOTAL** | **70%** | **85%** |

---

## ğŸ› Debugging Tests

```bash
# Ejecutar con debugger (pdb)
pytest --pdb

# Pausar en primer fallo
pytest -x --pdb

# Ejecutar con ipdb (mejor que pdb)
pip install ipdb
pytest --pdbcls=IPython.terminal.debugger:TerminalPdb

# Ver print statements y logging
pytest -s --log-cli-level=DEBUG
```

---

## ğŸ”§ ConfiguraciÃ³n CI/CD

Los tests se ejecutan automÃ¡ticamente en GitHub Actions:

```yaml
# .github/workflows/CI_pytest.yml
- name: Run Tests with Coverage
  run: |
    pytest --cov=app --cov-report=xml --cov-report=term-missing

- name: Upload Coverage
  uses: codecov/codecov-action@v3
  with:
    file: ./coverage.xml
```

---

## ğŸ“š Recursos

- [Pytest Documentation](https://docs.pytest.org/)
- [Coverage.py Documentation](https://coverage.readthedocs.io/)
- [Locust Documentation](https://docs.locust.io/)
- [Selenium Documentation](https://www.selenium.dev/documentation/)

---

**Ãšltima actualizaciÃ³n:** 2025-01-20
**Maintainer:** Materials Hub Team
